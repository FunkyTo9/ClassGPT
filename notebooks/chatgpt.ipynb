{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq llama-index openai langchain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import GPTSimpleVectorIndex, download_loader\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load OPENAI API KEY\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFReader = download_loader(\"PDFReader\")\n",
    "\n",
    "loader = PDFReader()\n",
    "documents = loader.load_data(file=Path('pdfs/lecture01-intro-2up.pdf'))\n",
    "#print(documents) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manual construction\n",
    "\n",
    "source: https://github.com/emptycrown/llama-hub/blob/main/loader_hub/file/pdf/base.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import re\n",
    "from io import BytesIO\n",
    "from llama_index import Document\n",
    "\n",
    "\n",
    "def parse_pdf(file: BytesIO):\n",
    "\n",
    "    pdf = PdfReader(file)\n",
    "    text_list = []\n",
    "    \n",
    "    # Get the number of pages in the PDF document\n",
    "    num_pages = len(pdf.pages)\n",
    "\n",
    "    # Iterate over every page\n",
    "    for page in range(num_pages):\n",
    "        # Extract the text from the page\n",
    "        page_text = pdf.pages[page].extract_text()\n",
    "        text_list.append(page_text)\n",
    "\n",
    "    text = \"\\n\".join(text_list)\n",
    "\n",
    "    return [Document(text)]\n",
    "\n",
    "\n",
    "with open('pdfs/lecture01-intro-2up.pdf', 'rb') as file:\n",
    "    manual_load = parse_pdf(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.langchain_helpers.chatgpt import ChatGPTLLMPredictor\n",
    "\n",
    "llm_predictor = ChatGPTLLMPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 1672 tokens\n",
      "> [build_index_from_documents] Total embedding token usage: 1672 tokens\n"
     ]
    }
   ],
   "source": [
    "index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save_to_disk('index.json')\n",
    "# load from disk\n",
    "index = GPTSimpleVectorIndex.load_from_disk('index.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  query chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1822 tokens\n",
      "> [query] Total LLM token usage: 1822 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 8 tokens\n",
      "> [query] Total embedding token usage: 8 tokens\n"
     ]
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "response = index.query(\"Summarize this lecture in bullet points\", llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>- The lecture is about Artificial Intelligence (AI).\n",
       "- It covers the definition of AI, general characteristics of intelligence, and different approaches to creating AI.\n",
       "- The history of AI is discussed, including early successes, disappointments, and recent advances.\n",
       "- Examples of AI applications are given, including games, mathematics, space exploration, autonomous driving, and scientific discovery.\n",
       "- AI's potential impact on society is mentioned, including concerns about AI surpassing human intelligence (the \"Singularity\").\n",
       "- The lecture provides a brief introduction to the study of AI.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1844 tokens\n",
      "> [query] Total LLM token usage: 1844 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 13 tokens\n",
      "> [query] Total embedding token usage: 13 tokens\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"Test my knowledge on this material with 3 questions and give me answers\", llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>1. What is AI?\n",
       "AI is the art of creating machines that perform functions that require intelligence when performed by humans. It is the study of the computations that make it possible to perceive, reason, and act. \n",
       "\n",
       "2. What are the four general characteristics of intelligence?\n",
       "The four general characteristics of intelligence are perception, action, reasoning, and learning. \n",
       "\n",
       "3. What is a rational agent according to the course?\n",
       "A rational agent is one that acts so as to achieve the best outcome, given the available information. It is an entity that perceives and acts, and the course is about designing such agents.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 1770 tokens\n",
      "> [query] Total LLM token usage: 1770 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n",
      "> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Slide 14 says that AI has defeated human champions in various games such as chess, checkers, poker, and Go. It also mentions how AI has proven a mathematical conjecture, assisted with logistics planning during the Gulf War, and controlled the scheduling of operations for spacecraft and Mars Exploration Rovers.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = index.query(\"What does slide 14 say about what AI can do?\", llm_predictor=llm_predictor)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f1e841692445df6c0f476977380d4c26cc40d52508098a18c340919add514d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
